# new_project - Анализ глобальных выбросов CO₂
Проект по анализу и визуализации данных о глобальных выбросах углекислого газа.
Ссылка на Data: https://disk.yandex.ru/d/iJy44WhoHY-y0w

Данный датасет содержит структурированную информацию о глобальных выбросах CO₂. Он состоит из 50 столбцов, некоторые из которых посвящены определению стран и регионов, другие - значениям выбросов по различным категориям, а также дополнительным столбцам для подробной классификации. Набор данных позволяет проводить всесторонний анализ выбросов с географической, экономической и отраслевой точек зрения, что делает его ценным для исследований, оценки политики и глобальных сравнений.

# Структура проекта
```
├── etl/ # ETL пакет 
│ ├── __init__.py
│ ├── extract.py              # Загрузка и валидация сырых данных
│ ├── transform.py            # Преобразование типов данных
│ ├── load.py                 # Запись в БД и сохранение в Parquet
│ ├── validate.py             # Валидация данных
│ └── main.py                 # Основной скрипт 
├── api_example/              # Пример работы с The Cat API
│ ├── README.md               # Документация к примеру API
│ ├── api_loader.py           # Скрипт загрузки данных с API
│ └── cat_images.csv          # Данные о котиках (ID, URL, размеры)
├── parse_example/            # Пример парсинга данных
│ ├── README.md               # Документация к примеру парсинга
│ └── data_parser.py          # Скрипт парсинга данных
├── notebooks/                # Ноутбуки
│   └── EDA.ipynb             # Exploratory Data Analysis
│   └── Notebook.ipynb        # Нотбук в доказательством того, что типы верные
├── .gitignore                # Игнорируемые файлы и папки
├── README.md                 # Основная документация проекта
└── environment.yml           # Конфигурация окружения Conda
```

# Установка и настройка окружения
Инструкция по созданию окружения conda из файла environment.yml
1. Установить conda.
2. Написать команду ```conda env create -f environment.yml``` в терминал.
3. Активировать окружение ```conda activate your-environment-name```

# Запуск скрипта
Используйте команду ```python data_loader.py```, чтобы посмотреть на вывод скрипта.

На рисунке ниже представлен результат работы скрипта `data_loader.py`

<img width="1026" height="519" alt="image" src="https://github.com/user-attachments/assets/62c12512-452b-41c7-b7a0-86a919d5e79b" />

Метод ```convert_dtypes()``` используется для преобразования столбцов DataFrame в наиболее подходящий тип данных, поддерживающий pd.NA для отсутствующих значений. Так как в Data 80 колонок, этот метод лучше всего подходит для преобразования типов DataFrame.

Здесь «наилучший из возможных» означает тип, наиболее подходящий для хранения значений. Например, это целочисленный тип pandas, если все значения являются целыми числами (или отсутствуют): столбец объектов Python, содержащих целые числа, преобразуется в Int64, а столбец значений NumPy int32 становится типом pandas Int32.

# ETL Package

### Запуск:
Перед запуском не забудьте настроить окружение, а затем вставить следующую команду:
```python -m etl.main --url "https://drive.google.com/uc?id=1C_iqgpDk2RqQJzV_5J2Nok8DfFMomVbQ" --limit 100```

Эта команда запускает полный ETL процесс: загружает данные по указанной ссылке, валидирует их на целостность, преобразует типы данных, а затем сохраняет результаты в CSV-файл в папке data/raw/, в Parquet-файл в data/processed/ и записывает до 100 строк в базу данных PostgreSQL.

На фото ниже представлен вывод ETL.

<img width="472" height="141" alt="image" src="https://github.com/user-attachments/assets/788c29b2-c8b5-43be-a059-1135e7e146eb" />

# EDA

Посмотреть анализ данных можно перейдя по ссылке - https://nbviewer.org/github/Svetlana88-n/new_project/blob/main/notebook/EDA.ipynb
